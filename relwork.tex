Recent sparse matrix multiplication studies focus on in-memory optimizations.
Williams et al.~\cite{Williams07} describe optimizations for sparse matrix
vector multiplication (SpMV) in multicore architectures. Yoo et al.~\cite{Yoo11}
and Boman et al.~\cite{Boman2013} optimize distributed SpMV for large
scale-free graphs with 2D partitioning to reduce communication between
machines. In contrast, sparse matrix dense matrix multiplication (SpMM) receives
less attention from the high-performance computing community. Even though
SpMM can be implemented with SpMV, SpMV fails to explore data locality in
SpMM. Aktulga et al.~\cite{Aktulga14} optimize SpMM with cache blocking.
Koanantakool et al.~\cite{Koanantakool16} experiment with different parallel
algorithms for sparse matrix dense matrix multiplication and analyze
their communication cost in distributed memory.
We advance SpMM with a focus on optimizations for semi-external memory.

Compressed row storage (CSR) and compressed column storage (CSC) formats are commonly
used sparse matrix formats in many numeric libraries, such as Intel MKL \cite{mkl}
and Trilinos \cite{trilinos}. However, these formats are not designed for graphs.
Sparse matrix multiplication with these formats on graphs incurs many random memory
accesses. %Other, more modern sparse matrix formats have been designed.
Sparsity \cite{Im04} designs a format that encodes both register blocking and cache blocking to
increase data reuse in the CPU cache for sparse matrix multiplication. Register blocking
requires explicit storage of zero values in register blocks. This strategy
wastes space and computation for graphs because graphs are sparse and
a vertex in a graph can connect to an arbitrary number of other vertices. Buluc et al.~\cite{Buluc08}
further advance sparse matrix format
by doubly compressed sparse column (DCSC) for hypersparse submatrices after 2D
partitioning on a sparse matrix. This format significantly reduces the storage
size of a 2D-partitioned sparse matrix. Our format further reduces the storage
size of a sparse matrix.

Abello et al.~\cite{Abello98} introduced the semi-external memory algorithmic
framework for graphs. Pearce et al.~\cite{Pearce10} implement several
semi-external memory graph traversal algorithms for SSDs. FlashGraph
\cite{FlashGraph} adopted the concept and performs graph algorithms with
vertex state in memory and edge lists on SSDs. This work extends the semi-external
memory concept to matrix operations.

GridGraph \cite{gridgraph} is a general-purpose graph processing framework on
a single machine
and scales to large graphs using disks. It performs 2D partitioning on a graph
to reduce CPU cache misses in graph analysis and deploys 2-level hierarchical
partitioning to reduce I/O. This graph engine is designed for graph
algorithms expressed as sparse matrix vector multiplication and keeps both
graphs and vertex computation state on disks. In contrast, our work focuses on
optimizations on sparse matrix dense matrix multiplication and performs this
operation in semi-external memory to reduce I/O, especially writes,
to SSDs. GridGraph runs slower than in-memory linear algebra libraries
such as Intel MKL \cite{mkl} and Trilinos Tpetra \cite{trilinos}.

Array databases such as SciDB \cite{scidb} and Rasdaman \cite{rasdaman} support
sparse matrix mutliplication. They perform matrix multiplication using CSR
formats \cite{SLACID}, similar to Intel MKL and Trilinos.  There has also been
preliminary research on accelerating matrix multiplication with GPUs \cite{Liu14},
showing that speedups are limited by I/O and setup costs and that benefits
are limited to compute dense operations.

%DZ TODO scidb cite -- http://www.odbms.org/wp-content/uploads/2014/04/The_Architecture_of_SciDB.pdf
% Array Store cite -- http://scidb.cs.washington.edu/paper/sigmod362-soroush.pdf

MapReduce \cite{MapReduce} is also commonly used for processing large graphs.
PEGASUS \cite{pegasus} is a popular graph processing engine built on MapReduce
and expresses graph algorithms as a generalized form of sparse matrix-vector
multiplication. GBase \cite{gbase} is a graph database built on MapReduce.
It optimizes the graph storage for graph queries and analysis and perform graphs
queries and analysis with sparse matrix vector multiplication.
Other works \cite{Liao14, Yin14, Liu10} implement non-negative matrix
factorization (NMF) with MapReduce. Although these MapReduce-based
implementations can scale to very large graphs, they run orders of
magnitude more slowly than optimized in-memory solutions, such as Trilinos and Intel MKL.

Zhou et al.~\cite{Zhou12} implement an LOBPCG \cite{Arbenz05} eigensolver in
an SSD cluster. Their implementation targets nuclear many-body Hamiltonian
matrices, which are much denser and have smaller dimensions than many sparse
graphs. Therefore, their solution stores the sparse matrix on SSDs and keep
the entire vector subspace in RAM. In contrast, our SEM-SpMM handles dense
matrices of different sizes and our eigensolver stores both the sparse matrix
and the vector subspace on SSDs.

The Trilinos project \cite{trilinos} has a large collection of numerical libraries.
The Tpetra library provides efficient sparse matrix operations such as sparse matrix
multiplication. The matrix implementations in Trilinos are optimized for
distributed memory.

Intel Math Kernel Library \cite{mkl} is an efficient and parallel linear
algebra library with matrix operations optimized for Intel
platforms. It provides an efficient sparse matrix multiplication
for regular sparse matrices. In contrast, our sparse matrix multiplication
optimizes for power-law graphs with near-random vertex connection.
