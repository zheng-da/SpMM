% What problem are you going to solve.
Sparse matrix multiplication is a very important computation with a wide variety
of applications in scientific computing, machine learning and graph analysis.
For example, matrix factorization algorithms on a sparse matrix such as
singular value decomposition (SVD) \cite{svd} and non-negative matrix
factorization (NMF) \cite{nmf} require sparse matrix multiplication.
Graph analysis algorithms such as PageRank \cite{pagerank} can be
formulated as sparse matrix multiplication or generalized sparse matrix
multiplication \cite{Mattson13}. Some of
the algorithms, such as PageRank and SVD, require sparse matrix vector
multiplication. Others, such as NMF, require sparse matrix dense
matrix multiplication.

We focus on sparse matrices derived from graphs because the largest sparse
matrices arise from graph datasets such as social networks and Web graphs.
For example, Facebook's social network has billions of vertices and
today's Web graphs are even much larger. These matrices inherit structure
from natural graphs. They are typically very sparse and have near-random
distribution for non-zero entries. They also have a power law distribution
that governs the number of non-zero entries per row and column.
We perform sparse matrix multiplication for graph
analysis such as community detection with NMF and spectral analysis with SVD.

% Why is it hard?

It is challenging to have an efficient implementation of sparse matrix
multiplication. This operation has very low computation density and its
performance is limited by memory access. As such, it usually achieves only
a small fraction of the peak performance of a modern processor \cite{Williams07}.

Sparse matrices derived from graphs impose additional challenges in
this operation. Many graphs have power-law distribution in vertex
degree, which causes load imbalance in sparse matrix multiplication. These
sparse matrices are also much sparser and have more random distribution of
non-zero entries than traditional sparse matrices that arise from scientific
computing. As such, many optimizations for traditional sparse matrices such
as register blocking and prefetching \cite{Williams07} increase storage size,
bring more data to CPU cache unnecessarily and hurt performance.
The commonly used sparse matrix storage formats such as CSR (compressed sparse
row) and CSC (compressed sparse column) leads to significant CPU cache misses
in sparse matrix multiplication due to near-random distribution of non-zero
entries as well as the sparsity and the enormous size of graphs. 
%Furthermore, graphs cannot be
%clustered or partitioned effectively \cite{leskovec} to localize access.
Therefore, sparse matrix multiplication on graphs is frequently the bottleneck
in an application.

%How have others addressed the problem?
Current research focuses on sparse matrix multiplication in memory
for small matrices and scaling to a large sparse matrix in a large cluster,
where the aggregate memory is sufficient to store the sparse matrix
\cite{Williams07, Yoo11, Boman2013}.
The distributed solution for sparse matrix multiplication leads to significant
network communication and network bandwidth is usually the bottleneck.
As such, this operation requires a fast network to achieve performance.
A supercomputer or a large cluster with a fast network is inaccessible or
too expensive for many users. In addition, the distributed solution imposes
challenges in achieving load balancing on power-law graphs.

%What is the nature of your solution?

On the other hand, a current trend for hardware design is to scale up
a single machine for high performance computing.
These machines typically have multiple processors with many CPU cores and
a large amount of memory. They are also equipped with fast flash
memory such as solid-state drives (SSDs) to further extend memory capacity.
This conforms to the node design for supercomputers \cite{Ang14}.

We explore a solution that scales sparse matrix dense matrix multiplication
(SpMM) on a multi-core machine with commodity SSDs and
perform SpMM in semi-external memory (SEM). The concept of semi-external memory
arose as a functional computing approach for graphs \cite{Abello98} in which
the vertex state of a graph is stored in memory and the edges accessed from
external memory. We introduce a similar construct for SpMM in which one or more
columns of a dense matrix are kept in memory and the sparse matrix is accessed
from external memory. In semi-external memory, we assume
that the memory of a machine is sufficient to keep at least one column
of the input dense matrix but is insufficient to hold the sparse matrix
and the dense matrices. Given fast SSDs, we demonstrate that the SEM
solution uses the resources of a multi-core machine well and
achieves performance comparable to state-of-the-art in-memory implementations
while increasing the scalability in proportion
to the ratio of non-zero entries to rows or columns in a sparse matrix.

% Why is it new/different/special?

We overcome many technical challenges to construct a sparse matrix
multiplication implementation on SSDs to achieve performance. Specifically,
SSDs are an order of magnitude slower in throughput and multiple orders of
magnitude slower in latency than DRAM. Furthermore, sequential I/O of SSDs
is still much faster
than random I/O \cite{safs} and reads are faster than writes. In addition,
SSDs wear out when we write data to them and random writes further shorten
the lives of SSDs \cite{sfs}. As such, our solution needs to sequentialize
I/O access and reduce I/O, especially writes.

Semi-external memory provides a scalable and efficient SpMM solution that
meets the I/O challenges and incorporates substantial computation optimizations
to achieve performance of SpMM on graphs in a NUMA (non-uniform memory
architecture) machine. During the computation, each
thread streams its own partitions of the sparse matrix from SSDs, maximizing
I/O throughput and avoiding thread synchronization. We buffer all
intermediate computation results in local memory, to reduce remote memory
access, and stream the output matrix to SSDs at most once, minimizing writes
to SSDs. We design a very compact sparse matrix format to accelerate retrieving
a sparse matrix from SSDs. Semi-external memory has memory constraints.
As such, we deploy only computation optimizations that require a small memory
footprint, e.g., fine-grain dynamic task scheduling to balance loads on
power-law graphs and cache blocking to increase CPU cache hits.

Given the sparsity and the enormous size of graphs, the dense matrices involved
in SpMM are massive and our semi-external memory solution adapts to
dense matrices with different numbers of columns. When the dense matrix is
larger than memory, we split it
vertically into multiple partitions so that each partition can fit in
memory. As such, the minimum memory requirement of our solution is $O(n)$,
where $n$ is the number of rows in the input dense matrix. By keeping more columns
in the dense matrix in memory, we reduce I/O from SSDs in SpMM. When the number
of columns in a dense matrix increases, SEM-SpMM becomes CPU bound, instead of
I/O bound, on fast SSDs.

We develop three important applications in scientific computing and graph
analysis
with our SEM-SpMM: PageRank \cite{pagerank}, eigensolver \cite{anasazi} and
non-negative matrix factorization \cite{nmf}. Each of them requires SpMM with
different numbers of columns in dense matrices, resulting in different
strategies of placing data in memory. With the three applications, we
demonstrate data placement choices for different memory capacities in a machine
and the impact of the memory size on the performance of the applications.

% What are it's key features?

The main contributions of this paper are:
\begin{itemize}
	\item We scale SpMM in semi-external memory with SSDs and tailor runtime
		optimizations that meet memory constraints in the semi-external memory
		setting and asymmetric I/O access of SSDs.
	\item We deploy a compact sparse matrix format to reduce the amount of
		I/O and alleviate I/O as the bottleneck of the system.
	\item We deploy a fine-grain dynamic load balancing scheme for sparse
		matrices with power-law distribution in non-zero entries.
	\item We optimize SpMM for dense matrices with various numbers of columns
		and extends SEM-SpMM to large dense matrices that cannot fit in memory
		by vertically partitioning the dense matrices.
%	\item We demonstrate that SpMM in semi-external memory, coupled with SSDs,
%		meets or even exceeds the performance of highly optimized in-memory
%		implementations. Our SEM-SpMM achieves almost 100\% performance of our
%		in-memory implementation on a large parallel machine. Even for SpMV,
%		our SEM implementation achieves at least 65\% performance of our
%		in-memory implementation and outperforms Trilinos \cite{trilinos} and
%		MKL \cite{mkl} by a factor of $2-9$.
%	\item The applications implemented with our SpMM significantly outperform
%		the state-of-the-art implementations of these applications.
%	\item The code of this work is released as open source at http://flashx.io.
\end{itemize}

Our result shows that for real-world sparse graphs, our SEM-SpMM achieves almost
100\% performance of our in-memory implementation on a large parallel machine
with 48 CPU cores when the dense matrix has more than four columns. Even for
SpMV, our SEM implementation achieves at least 65\% performance of our in-memory
implementation and outperforms Trilinos \cite{trilinos} and MKL \cite{mkl} by
a factor of $2-9$. The applications implemented with our SpMM significantly
outperform the state-of-the-art implementations of these applications. As such,
we conclude that semi-external memory coupled with SSDs delivers an efficient
solution for large-scale sparse matrix multiplication. It serves
as a building block and offers new design possibilities for large-scale
data analysis, replacing memory with larger, cheaper, more energy-efficient SSDs
and processing bigger problems on fewer machines. The code of this work is
released as open source at http://flashx.io.
