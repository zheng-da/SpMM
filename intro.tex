% What problem are you going to solve.
Sparse matrix multiplication is a very important computation with a wide variety
of applications in scientific computing, machine learning and data mining.
For example, matrix factorization algorithms on a sparse matrix such as
singular value decomposition (SVD) \cite{svd} and non-negative matrix
factorization (NMF) \cite{nmf} requires sparse matrix multiplication.
Graph analysis algorithms such as PageRank \cite{pagerank} can be
formulated as sparse matrix multiplication or generalized sparse matrix
multiplication \cite{Mattson13}. Some of
the algorithms, such as PageRank and SVD, require sparse matrix vector
multiplication. Others, such as NMF, require sparse matrix dense
matrix multiplication.

The largest sparse matrices arise from graph datasets such as social networks
and Web graphs, in which one performs
sparse matrix multiplication for graph analysis such as community detection
with NMF and spectral analysis with SVD. These matrices inherit structure
from natural graphs. Specifically,
these matrices are typically very sparse and have near-random distribution
for non-zero entries. They also have a power law distribution that governs
the number of non-zero entries per row and column.

% Why is it hard?

It is challenging to have an efficient implementation of sparse matrix
multiplication, especially for sparse matrices that encode real-world graphs.
Sparse matrix multiplication has very low computation density and its performance
is limited by memory access. As such, this operation usually achieves only
a small fraction of the peak performance of a modern processor \cite{Williams07}.
It becomes even more challenging to perform this operation on graphs due to
random memory access caused by near-random vertex connection and load imbalancing
caused by the power-law distribution in vertex degree. Furthermore, many
real-world graphs
are enormous. For example, Facebook's social network has billions of vertices
and today's Web graphs are even much larger. %Furthermore, graphs cannot be
%clustered or partitioned effectively \cite{leskovec} to localize access.
Therefore, sparse matrix multiplication on graphs is frequently the bottleneck
in an application.

%How have others addressed the problem?
Current research focuses on sparse matrix vector multiplication (SpMV) in memory
for small matrices and scaling to a large sparse matrix in a large cluster,
where the aggregate memory is sufficient to store the sparse matrix
\cite{Williams07, Yoo11, Boman2013}.
The distributed solution for sparse matrix multiplication leads to significant
network communication and network bandwidth is usually the bottleneck.
As such, this operation requires a fast network to achieve performance.
A supercomputer or a large cluster with a fast network is inaccessible or
too expensive for many users.

%What is the nature of your solution?

On the other hand, a current trend for hardware design is to scale up
a single machine for high performance computing.
These machines typically have multiple processors with many CPU cores and
a large amount of memory. They are also equipped with fast flash
memory such as solid-state drives (SSDs) to further extend memory capacity.
This conforms to the node design for supercomputers \cite{Ang14}.

We explore a solution that scales sparse matrix dense matrix multiplication
(SpMM) on a multi-core machine with commodity SSDs and
perform SpMM in semi-external memory (SEM). The concept of semi-external memory
arose as a functional computing approach for graphs \cite{Abello98} in which
the vertex state of a graph is stored in memory and the edges accessed from
external memory. We introduce a similar construct for SpMM in which one or more
columns of a dense matrix are kept in memory and the sparse matrix is accessed
from external memory. In semi-external memory, we assume
that the memory of a machine is sufficient to keep at least one column
of the input dense matrix but is insufficient to hold the sparse matrix
and the dense matrices. Even though SpMM could be implemented with
SpMV, such an implementation would fail to explore data locality in SpMM and
result in higher I/O access in semi-external memory. We optimize SpMM directly
to overcome these problems. Given fast SSDs, we demonstrate that the SEM
solution uses the resources of a multi-core machine well and
achieves performance comparable to state-of-the-art in-memory implementations
while increasing the scalability in proportion
to the ratio of non-zero entries to rows or columns in a sparse matrix.

% Why is it new/different/special?

We overcome many technical challenges to construct a sparse matrix
multiplication implementation on SSDs to achieve performance. Specifically,
SSDs are an order of magnitude slower in throughput and multiple orders of
magnitude slower in latency than DRAM. Furthermore, sequential I/O of SSDs
is still much faster
than random I/O \cite{safs} and reads are faster than writes. In addition,
SSDs wear out when we write data to them and random writes further shorten
the lives of SSDs \cite{sfs}. As such, our solution needs to sequentialize
I/O access and reduce I/O, especially writes.

Semi-external memory provides a scalable and efficient SpMM solution that
meets the I/O challenges and incorporates substantial computation optimizations.
During the computation, each
thread streams its own partitions of the sparse matrix from SSDs, maximizing
I/O throughput and avoiding thread synchronization. We buffer all
intermediate computation results in memory and stream the output matrix to SSDs
at most once, minimizing writes to SSDs. We design a very compact sparse matrix
format to accelerate retrieving a sparse matrix from SSDs.
Semi-external memory has memory constraints. As such, we deploy
only computation optimizations that require a small memory footprint, such as
dynamic task scheduling and cache blocking.

Our semi-external memory solution adapts to machines with different memory
capacities. When the dense matrix is larger than memory, we split it
vertically into multiple partitions so that each partition can fit in
memory. As such, the minimum memory requirement of our solution is $O(n)$,
where $n$ is the number of rows in the input dense matrix. By keeping more columns
in the dense matrix in memory, we reduce I/O from SSDs in SpMM. When the number
of columns in a dense matrix increases, SEM SpMM becomes CPU bound, instead of
I/O bound on fast SSDs.

We develop three important applications in scientific computing and data mining
with our SEM SpMM: PageRank \cite{pagerank}, eigensolver \cite{anasazi} and
non-negative matrix factorization \cite{nmf}. Each of them requires SpMM with
different numbers of columns in dense matrices, resulting in different
strategies of placing data in memory. With the three applications, we
demonstrate data placement choices for different memory capacities in a machine
and the impact of the memory size on the performance of the applications.

% What are it's key features?

Our result shows that for real-world sparse graphs, our SEM SpMM achieves almost
100\% performance of our in-memory implementation on a large parallel machine
with 48 CPU cores when the dense matrix has more than four columns. Even for
SpMV, our SEM implementation achieves at least 65\% performance of our in-memory
implementation and outperforms Trilinos \cite{trilinos} and MKL \cite{mkl} by
a factor of $2-9$. The applications implemented with our SpMM significantly
outperform the state-of-the-art implementations of these applications. As such,
we conclude that semi-external memory coupled with SSDs delivers an efficient
solution for large-scale sparse matrix multiplication. It serves
as a building block and offers new design possibilities for large-scale
data analysis, replacing memory with larger, cheaper, more energy-efficient SSDs
and processing bigger problems on fewer machines. The code of this work is
released as open source at http://flashx.io.
